{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pawan-cpu/STTP-Intel-Edge/blob/main/Pawank_Sttp_Intel_tflite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d6YB6Mh93Vc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLKpmZICaWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115f7482-7157-4f49-d74e-15eab631db4f"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sys import getsizeof\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly import tools\n",
        "import tempfile\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "IxrlOlJCVV86"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VULHpvbVl0N"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymcbpqPdLJxW"
      },
      "source": [
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfRLdF_LKUK"
      },
      "source": [
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
        "    elif unit == \"MB\":\n",
        "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
        "    else:\n",
        "        return print('File size: ' + str(size) + ' bytes')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "[Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "source": [
        "fashion_mnist = keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "source": [
        "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "#                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5k_xz1CaWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b79a8cd-91b6-4299-fe02-40e6f7e80b91"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFYHB2mCaWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed08c41c-a2bb-4017-d49e-f2f1893f0afe"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnCTHz4CaWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93cb5fd-0ef0-496c-c16a-b7b9f4c15bab"
      },
      "source": [
        "np.unique(test_labels)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqTxmbVBASQF"
      },
      "source": [
        "# Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KFnYlcwCaWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a466d128-7e32-4878-e330-032c39e657be"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJmPr5-ACaWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f09233-2d07-4d2a-d03a-cb8fdcfe185e"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4VEw8Ud9Quh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "22362e4c-c2bd-43e9-d605-786cc51ca943"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[88])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW5WzIPlCaWv"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjeb1zV6MoVa"
      },
      "source": [],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build & Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    Flatten(input_shape=(32, 32,3)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(256,activation='relu'),\n",
        "    Dense(10)\n",
        "])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdOHE8CLNV1_",
        "outputId": "057c7767-ab55-43fd-be44-cd4bbf1becec"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               393344    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 428,938\n",
            "Trainable params: 428,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "model.compile(optimizer='SGD',\n",
        "              loss= SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvwvpA64CaW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e8e9ff-8210-458e-ee02-7b9a3466d0d0"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10,validation_data=(test_images,test_labels))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9103 - accuracy: 0.3141 - val_loss: 1.7904 - val_accuracy: 0.3539\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7232 - accuracy: 0.3859 - val_loss: 1.6675 - val_accuracy: 0.4091\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6390 - accuracy: 0.4172 - val_loss: 1.6692 - val_accuracy: 0.4001\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5826 - accuracy: 0.4402 - val_loss: 1.5928 - val_accuracy: 0.4331\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5393 - accuracy: 0.4567 - val_loss: 1.6399 - val_accuracy: 0.4277\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5036 - accuracy: 0.4681 - val_loss: 1.5442 - val_accuracy: 0.4554\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4737 - accuracy: 0.4788 - val_loss: 1.4741 - val_accuracy: 0.4766\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4481 - accuracy: 0.4877 - val_loss: 1.4776 - val_accuracy: 0.4827\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4235 - accuracy: 0.4958 - val_loss: 1.4549 - val_accuracy: 0.4812\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4004 - accuracy: 0.5064 - val_loss: 1.5126 - val_accuracy: 0.4560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9432442310>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN MODEL"
      ],
      "metadata": {
        "id": "9IXx4OWkVD3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_ROWS = 32\n",
        "IMG_COLS = 32\n",
        "# Model\n",
        "model = keras.Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sqCaAnFoVHCL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl5OXbfbVO8H",
        "outputId": "68c4d70a-04cf-48fb-8558-34af1fe4a7ce"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 356,810\n",
            "Trainable params: 356,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "NO_EPOCHS = 10\n",
        "train_model = model.fit(train_images, train_labels,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(test_images,test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XUrEtE0VO-s",
        "outputId": "437cb378-7701-4c88-c451-a1ec4f2cdbba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 1.4004 - accuracy: 0.4949 - val_loss: 1.1504 - val_accuracy: 0.5890\n",
            "Epoch 2/10\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 1.0039 - accuracy: 0.6462 - val_loss: 1.0026 - val_accuracy: 0.6452\n",
            "Epoch 3/10\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.8491 - accuracy: 0.7001 - val_loss: 0.9325 - val_accuracy: 0.6799\n",
            "Epoch 4/10\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.7409 - accuracy: 0.7389 - val_loss: 0.8656 - val_accuracy: 0.7016\n",
            "Epoch 5/10\n",
            "3125/3125 [==============================] - 13s 4ms/step - loss: 0.6497 - accuracy: 0.7688 - val_loss: 0.8762 - val_accuracy: 0.7054\n",
            "Epoch 6/10\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.5692 - accuracy: 0.8001 - val_loss: 0.9591 - val_accuracy: 0.6925\n",
            "Epoch 7/10\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.4939 - accuracy: 0.8255 - val_loss: 0.9413 - val_accuracy: 0.7027\n",
            "Epoch 8/10\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.4314 - accuracy: 0.8468 - val_loss: 0.9891 - val_accuracy: 0.7138\n",
            "Epoch 9/10\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.3761 - accuracy: 0.8666 - val_loss: 1.0782 - val_accuracy: 0.7002\n",
            "Epoch 10/10\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.3271 - accuracy: 0.8840 - val_loss: 1.1928 - val_accuracy: 0.6909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trace(x,y,ylabel,color):\n",
        "        trace = go.Scatter(\n",
        "            x = x,y = y,\n",
        "            name=ylabel,\n",
        "            marker=dict(color=color),\n",
        "            mode = \"markers+lines\",\n",
        "            text=x\n",
        "        )\n",
        "        return trace\n",
        "    \n",
        "def plot_accuracy_and_loss(train_model):\n",
        "    hist = train_model.history\n",
        "    acc = hist['accuracy']\n",
        "    val_acc = hist['val_accuracy']\n",
        "    loss = hist['loss']\n",
        "    val_loss = hist['val_loss']\n",
        "    epochs = list(range(1,len(acc)+1))\n",
        "    \n",
        "    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n",
        "    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n",
        "    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n",
        "    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n",
        "   \n",
        "    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n",
        "                                                             'Training and validation loss'))\n",
        "    fig.append_trace(trace_ta,1,1)\n",
        "    fig.append_trace(trace_va,1,1)\n",
        "    fig.append_trace(trace_tl,1,2)\n",
        "    fig.append_trace(trace_vl,1,2)\n",
        "    fig['layout']['xaxis'].update(title = 'Epoch')\n",
        "    fig['layout']['xaxis2'].update(title = 'Epoch')\n",
        "    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n",
        "    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n",
        "\n",
        "    \n",
        "    iplot(fig, filename='accuracy-loss')\n",
        "\n",
        "plot_accuracy_and_loss(train_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "-6oHHw1tW64t",
        "outputId": "4b102ba1-c86f-409a-cc80-953214778cb4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ba410bb8-a17e-4eed-ab11-deae87c6c69f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ba410bb8-a17e-4eed-ab11-deae87c6c69f\")) {                    Plotly.newPlot(                        \"ba410bb8-a17e-4eed-ab11-deae87c6c69f\",                        [{\"marker\":{\"color\":\"Green\"},\"mode\":\"markers+lines\",\"name\":\"Training accuracy\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],\"x\":[1,2,3,4,5,6,7,8,9,10],\"xaxis\":\"x\",\"y\":[0.4948599934577942,0.6462200284004211,0.7001199722290039,0.738860011100769,0.7688000202178955,0.8000800013542175,0.8254600167274475,0.8467599749565125,0.866599977016449,0.8839600086212158],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"Red\"},\"mode\":\"markers+lines\",\"name\":\"Validation accuracy\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],\"x\":[1,2,3,4,5,6,7,8,9,10],\"xaxis\":\"x\",\"y\":[0.5889999866485596,0.6452000141143799,0.6798999905586243,0.7016000151634216,0.7053999900817871,0.6924999952316284,0.7027000188827515,0.7138000130653381,0.7002000212669373,0.6909000277519226],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"Blue\"},\"mode\":\"markers+lines\",\"name\":\"Training loss\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],\"x\":[1,2,3,4,5,6,7,8,9,10],\"xaxis\":\"x2\",\"y\":[1.4004102945327759,1.0038670301437378,0.849122166633606,0.7408534288406372,0.6497350931167603,0.5691593289375305,0.49385973811149597,0.43136823177337646,0.37614706158638,0.32712143659591675],\"yaxis\":\"y2\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"Magenta\"},\"mode\":\"markers+lines\",\"name\":\"Validation loss\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],\"x\":[1,2,3,4,5,6,7,8,9,10],\"xaxis\":\"x2\",\"y\":[1.1504138708114624,1.0026005506515503,0.932468831539154,0.8656209707260132,0.8762481212615967,0.9591031074523926,0.9412699341773987,0.9890862107276917,1.078179955482483,1.1928232908248901],\"yaxis\":\"y2\",\"type\":\"scatter\"}],                        {\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training and validation accuracy\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training and validation loss\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"range\":[0,1],\"title\":{\"text\":\"Accuracy\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"range\":[0,1],\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ba410bb8-a17e-4eed-ab11-deae87c6c69f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADDING DROPOUT and Reducing OVERFITTING"
      ],
      "metadata": {
        "id": "dt_tIembYgWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = keras.Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# Add dropouts to the model\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Add dropouts to the model\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# Add dropouts to the model\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Add dropouts to the model\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "uY-Wq6WmW6_6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgXyoJE8W7HO",
        "outputId": "c083aa2a-2f7b-4747-a7a1-195232357619"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               262272    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 356,234\n",
            "Trainable params: 356,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "NO_EPOCHS = 10\n",
        "train_model = model.fit(train_images, train_labels,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(test_images,test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "pJAAlVhYW7OP",
        "outputId": "be4b3880-5c2a-47e3-d895-cc8d8b770a42"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32, name='conv2d_9_input'), name='conv2d_9_input', description=\"created by layer 'conv2d_9_input'\"), but it was called on an input with incompatible shape (16, 32, 32, 3).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-a84cd5e5d5e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNO_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                   validation_data=(test_images,test_labels))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 249, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_9\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (16, 32, 32, 3)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n       inputs=tf.Tensor(shape=(16, 32, 32, 3), dtype=float32)\n       training=True\n       mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy_and_loss(train_model)\n"
      ],
      "metadata": {
        "id": "Zfzgw0GvW7WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n4_BRNKLRwo"
      },
      "source": [
        "KERAS_MODEL_NAME = \"tf_model_fashion_mnist.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_3Y3F4GBWud"
      },
      "source": [
        "model.save(KERAS_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19sd1FJkCHID"
      },
      "source": [
        "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIuCg2nyWsvs"
      },
      "source": [
        "keras_model_size = get_file_size(KERAS_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_deKtkhCHMu"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy is {}%'.format(round(100*test_acc, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL PRUNING"
      ],
      "metadata": {
        "id": "tgtduvDpXUJB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsZROpNYMWQ0"
      },
      "source": [
        "You will apply pruning to the whole model and see this in the model summary.\n",
        "\n",
        "In this example, you start the model with 50% sparsity (50% zeros in weights)\n",
        "and end with 80% sparsity.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "metadata": {
        "id": "jchkIq9QXW1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "  \n",
        "model_for_pruning.fit(train_images, train_labels,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ],
      "metadata": {
        "id": "WSl0Pds3XXRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Pruned test accuracy:', model_for_pruning_accuracy)"
      ],
      "metadata": {
        "id": "b3vGkS7IXXT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FgNP4rbOLH8"
      },
      "source": [
        "Both `tfmot.sparsity.keras.strip_pruning` and applying a standard compression algorithm (e.g. via gzip) are necessary to see the compression\n",
        "benefits of pruning.\n",
        "\n",
        "*   `strip_pruning` is necessary since it removes every tf.Variable that pruning only needs during training, which would otherwise add to model size during inference\n",
        "*   Applying a standard compression algorithm is necessary since the serialized weight matrices are the same size as they were before pruning. However, pruning makes most of the weights zeros, which is\n",
        "added redundancy that algorithms can utilize to further compress the model.\n",
        "\n",
        "First, create a compressible model for TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)"
      ],
      "metadata": {
        "id": "7VoCCaNyXXZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "metadata": {
        "id": "T9F7CUh8YabX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "metadata": {
        "id": "egGKmrOpYjL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ],
      "metadata": {
        "id": "i7kLwNLLYlaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_and_pruned_tflite_model)\n",
        "\n",
        "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
        "\n",
        "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ],
      "metadata": {
        "id": "Xk1FhMrTYqxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on ever y image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32).reshape(-1,28,28,1)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "QoZNvOdkYqzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
        "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
      ],
      "metadata": {
        "id": "AEPBY3EwYq2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BFE9lvwLfgv"
      },
      "source": [
        "# TF Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORAx4Yc7LjwM"
      },
      "source": [
        "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY57t7EwCW8P"
      },
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = tf_lite_converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZxnt1IsCXBb"
      },
      "source": [
        "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtIdP296CXFl"
      },
      "source": [
        "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRScWYLIWmkI"
      },
      "source": [
        "tflite_file_size = get_file_size(TF_LITE_MODEL_FILE_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_gttI3-M45M"
      },
      "source": [
        "# Check Input Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJXJuGLFGfjB"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_X-k46vMzAt"
      },
      "source": [
        "# Resize Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6wo8RNFGpXw"
      },
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 28, 28,1))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsv7ROq8Gf0f"
      },
      "source": [
        "test_images.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM1alowAHy2d"
      },
      "source": [
        "test_imgs_numpy = np.array(test_images, dtype=np.float32).reshape(-1,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JBxCCNTTnft"
      },
      "source": [
        "test_imgs_numpy.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm4bxTIwHErB"
      },
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
        "interpreter.invoke()\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRKoF30HIZP2"
      },
      "source": [
        "acc = accuracy_score(prediction_classes, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZIF6OenI_5i"
      },
      "source": [
        "print('Test accuracy TFLITE model is {}%'.format(round(100*acc, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tNSVxOHWfPY"
      },
      "source": [
        "tflite_file_size/keras_model_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6CZhJbUY44n"
      },
      "source": [
        "# TF Lite Model Float 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhpWvf2KY-va"
      },
      "source": [
        "TF_LITE_MODEL_FLOAT_16_FILE_NAME = \"tf_lite_float_16_model.tflite\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzBgcOfGY-32"
      },
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_model = tf_lite_converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-OTCqGzZGkd"
      },
      "source": [
        "tflite_model_name = TF_LITE_MODEL_FLOAT_16_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLWOTWT-ZGnD"
      },
      "source": [
        "convert_bytes(get_file_size(TF_LITE_MODEL_FLOAT_16_FILE_NAME), \"KB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s70HjhmYZGqf"
      },
      "source": [
        "tflite_float_16_file_size = get_file_size(TF_LITE_MODEL_FLOAT_16_FILE_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roa0xXtdZGsq"
      },
      "source": [
        "tflite_float_16_file_size/keras_model_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFijAawdZeyA"
      },
      "source": [
        "tflite_float_16_file_size/tflite_file_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXrlI_NfZyZr"
      },
      "source": [
        "# TF Lite Size Quantized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoTxxLp2Ze0b"
      },
      "source": [
        "TF_LITE_SIZE_QUANT_MODEL_FILE_NAME = \"tf_lite_quant_model.tflite\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLzVy5BEZ7dK"
      },
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = tf_lite_converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFx8bVTGZ7fk"
      },
      "source": [
        "tflite_model_name = TF_LITE_SIZE_QUANT_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNBKgf-XZ7iN"
      },
      "source": [
        "convert_bytes(get_file_size(TF_LITE_SIZE_QUANT_MODEL_FILE_NAME), \"KB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRpw-azsZ7lD"
      },
      "source": [
        "tflite_float_quant_file_size = get_file_size(TF_LITE_SIZE_QUANT_MODEL_FILE_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEUM1ApdZe3T"
      },
      "source": [
        "tflite_float_quant_file_size/keras_model_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIdMzivLY-7J"
      },
      "source": [
        "tflite_float_quant_file_size/ tflite_float_16_file_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjEiZWfvaoGW"
      },
      "source": [
        "# Accuracy of the Quantized Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBIKxBccatZj"
      },
      "source": [
        "# Check Input Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMVMXOHpar5z"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_SIZE_QUANT_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqvlZxiSa2I2"
      },
      "source": [
        "# Resize Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQDZyidSar8s"
      },
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 28, 28,1))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCGHzlitar_r"
      },
      "source": [
        "test_images.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wFRpCMfa6Xx"
      },
      "source": [
        "test_imgs_numpy = np.array(test_images, dtype=np.float32).reshape(-1,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOY13_oIa6aR"
      },
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
        "interpreter.invoke()\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmcpKhSsa6di"
      },
      "source": [
        "acc = accuracy_score(prediction_classes, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1fwddHqa6gw"
      },
      "source": [
        "print('Test accuracy TFLITE Quantized model is {}%'.format(round(100*acc, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3XY64JciI5V"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}